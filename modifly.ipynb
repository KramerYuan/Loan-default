{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "warnings.filterwarnings('ignore')\n",
    "# 数据读取\n",
    "train_data = pd.read_csv('E:/Loan/train.csv')\n",
    "test_data = pd.read_csv('E:/Loan/testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签\n",
    "label = train_data[\"isDefault\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练集和测试集进行连接\n",
    "data = pd.concat([train_data, test_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "id\t为贷款清单分配的唯一信用证标识\n",
    "loanAmnt\t贷款金额    ----连续变量，直接使用\n",
    "term\t贷款期限（year） ----离散变量，直接使用\n",
    "interestRate\t贷款利率 ----连续型变量，直接使用\n",
    "installment\t分期付款金额   ----连续型变量，直接使用\n",
    "grade\t贷款等级    ----有优先级的，用labelEncode编码\n",
    "subGrade\t贷款等级之子级  ----有优先级的，用labelEncode编码\n",
    "employmentTitle\t就业职称   ----类别特征，但是有29W种，使用labelEncode编码(暂时不用)\n",
    "employmentLength\t就业年限（年）   ----转换成0-10的int类型\n",
    "homeOwnership\t借款人在登记时提供的房屋所有权状况  ----离散变量，直接使用\n",
    "annualIncome\t年收入 ----连续型变量，直接使用\n",
    "verificationStatus\t验证状态  ----离散型变量，直接使用\n",
    "issueDate\t贷款发放的月份   ----提取时间特征\n",
    "purpose\t借款人在贷款申请时的贷款用途类别  ----类别特征，无优先级，onehot\n",
    "postCode\t借款人在贷款申请中提供的邮政编码的前3位数字  ----类别特征，无优先级，onehot(暂时不用)\n",
    "regionCode\t地区编码  ----类别特征，无优先级，onehot\n",
    "dti\t债务收入比   ----连续型特征，直接使用\n",
    "delinquency_2years\t借款人过去2年信用档案中逾期30天以上的违约事件数   ----连续型特征，直接使用\n",
    "ficoRangeLow\t借款人在贷款发放时的fico所属的下限范围  ----连续型变量\n",
    "ficoRangeHigh\t借款人在贷款发放时的fico所属的上限范围  ----连续型变量--可以提取平均值特征\n",
    "openAcc\t借款人信用档案中未结信用额度的数量   ----连续特征，直接使用\n",
    "pubRec\t贬损公共记录的数量 -----连续特征，直接使用\n",
    "pubRecBankruptcies\t公开记录清除的数量  ----连续特征，直接使用\n",
    "revolBal\t信贷周转余额合计    ----连续特征，直接使用\n",
    "revolUtil\t循环额度利用率，或借款人使用的相对于所有可用循环信贷的信贷金额  ----连续特征，直接使用\n",
    "totalAcc\t借款人信用档案中当前的信用额度总数 ----连续特征，直接使用\n",
    "initialListStatus\t贷款的初始列表状态   ----离散型变量，直接使用\n",
    "applicationType\t表明贷款是个人申请还是与两个共同借款人的联合申请 ----离散型变量，直接使用\n",
    "earliesCreditLine\t借款人最早报告的信用额度开立的月份 ----提取年份和月份\n",
    "title\t借款人提供的贷款名称    ----暂时不用\n",
    "policyCode\t公开可用的策略_代码=1新产品不公开可用的策略_代码=2   ----全部为1无用特征\n",
    "n系列匿名特征\t匿名特征n0-n14，为一些贷款人行为计数特征的处理\n",
    "n11和n12相差悬殊暂时舍弃该特征\n",
    "其余特征为连续特征直接使用\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除dti为负值的数据(经验证，该数据有两条属于训练集)\n",
    "# data = data.drop(data[data[\"dti\"] < 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年应还\n",
    "data[\"year_due\"] = data[\"dti\"] * data[\"annualIncome\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DtiFun(x):\n",
    "    if x < 36:\n",
    "        return 0\n",
    "    elif x < 100:\n",
    "        return 1\n",
    "    elif x < 1000:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "# 根据dti判断是否属于健康范围\n",
    "data[\"dti_grade\"] = data[\"dti\"].apply(DtiFun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贷款时间总收入占贷款金额的比重\n",
    "data[\"loanAmnt_annuallncome_rate\"] = (data[\"term\"] * data[\"annualIncome\"]) / data[\"loanAmnt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据职称分类算平均年收入\n",
    "temp = data[[\"employmentTitle\", \"annualIncome\"]].groupby(\"employmentTitle\").mean()\n",
    "temp = temp.rename(columns={\"annualIncome\":\"employmentTitle_annualIncome_aver\"})\n",
    "data = pd.merge(data,temp,how=\"left\",on=\"employmentTitle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 标签区间特征\n",
    "# 贷款期限——违约率\n",
    "temp = pd.DataFrame(data.groupby([\"term\"])[\"isDefault\"].sum() / data.groupby([\"term\"])[\"isDefault\"].count())\n",
    "temp = temp.rename(columns={\"isDefault\":\"term_isDefault_ave\"})\n",
    "data = pd.merge(data,temp,how=\"left\",on=\"term\")\n",
    "\n",
    "# 贷款金额——违约率\n",
    "# temp = pd.DataFrame(data.groupby([\"loanAmnt\"])[\"isDefault\"].sum() / data.groupby([\"loanAmnt\"])[\"isDefault\"].count())\n",
    "# temp = temp.rename(columns={\"isDefault\":\"loanAmnt_isDefault_ave\"})\n",
    "# data = pd.merge(data,temp,how=\"left\",on=\"loanAmnt\")\n",
    "\n",
    "# # 职称——违约率\n",
    "# temp = pd.DataFrame(data.groupby([\"employmentTitle\"])[\"isDefault\"].sum() / data.groupby([\"employmentTitle\"])[\"isDefault\"].count())\n",
    "# temp = temp.rename(columns={\"isDefault\":\"employmentTitle_isDefault_ave\"})\n",
    "# data = pd.merge(data,temp,how=\"left\",on=\"employmentTitle\")\n",
    "\n",
    "# # 就业年限——违约率\n",
    "# temp = pd.DataFrame(data.groupby([\"employmentLength\"])[\"isDefault\"].sum() / data.groupby([\"employmentLength\"])[\"isDefault\"].count())\n",
    "# temp = temp.rename(columns={\"isDefault\":\"employmentLength_isDefault_ave\"})\n",
    "# data = pd.merge(data,temp,how=\"left\",on=\"employmentLength\")\n",
    "\n",
    "# # 房屋所有权——违约率\n",
    "# temp = pd.DataFrame(data.groupby([\"homeOwnership\"])[\"isDefault\"].sum() / data.groupby([\"homeOwnership\"])[\"isDefault\"].count())\n",
    "# temp = temp.rename(columns={\"isDefault\":\"homeOwnership_isDefault_ave\"})\n",
    "# data = pd.merge(data,temp,how=\"left\",on=\"homeOwnership\")\n",
    "\n",
    "# 年收入——违约率\n",
    "# temp = pd.DataFrame(data.groupby([\"annualIncome\"])[\"isDefault\"].sum() / data.groupby([\"annualIncome\"])[\"isDefault\"].count())\n",
    "# temp = temp.rename(columns={\"isDefault\":\"annualIncome_isDefault_ave\"})\n",
    "# data = pd.merge(data,temp,how=\"left\",on=\"annualIncome\")\n",
    "\n",
    "# # 邮编——违约率\n",
    "# temp = pd.DataFrame(data.groupby([\"postCode\"])[\"isDefault\"].sum() / data.groupby([\"postCode\"])[\"isDefault\"].count())\n",
    "# temp = temp.rename(columns={\"isDefault\":\"postCode_isDefault_ave\"})\n",
    "# data = pd.merge(data,temp,how=\"left\",on=\"postCode\")\n",
    "\n",
    "# # 邮编——违约率\n",
    "# temp = pd.DataFrame(data.groupby([\"dti\"])[\"isDefault\"].sum() / data.groupby([\"dti\"])[\"isDefault\"].count())\n",
    "# temp = temp.rename(columns={\"isDefault\":\"dti_isDefault_ave\"})\n",
    "# data = pd.merge(data,temp,how=\"left\",on=\"dti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.01      1\n",
       "15.69      1\n",
       "16.08      1\n",
       "16.31      1\n",
       "16.47      1\n",
       "          ..\n",
       "1618.03    1\n",
       "1647.03    1\n",
       "1691.28    1\n",
       "1714.54    4\n",
       "1715.42    2\n",
       "Name: installment, Length: 77132, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 月收入\n",
    "data['monthincome'] = data['annualIncome'] / 12\n",
    "\n",
    "# 月分期付款金额 / 月收入\n",
    "data[\"monthly_installment_amount\"] = data[\"installment\"] / data[\"monthincome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fico特征\n",
    "data[\"ficoRangeAve\"] = data[\"ficoRangeLow\"] + (data[\"ficoRangeHigh\"] - data[\"ficoRangeLow\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年利息 interestRate * loanAmnt\n",
    "data['allmoney'] = list(map(lambda x,y:x*y,data['loanAmnt'],\n",
    "                                data['interestRate']/100))\n",
    "\n",
    "# 年利息/年收入 \n",
    "data['howlong_return'] = data['allmoney'].values / data['annualIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贷款金额 / 信用额度总数\n",
    "data[\"LoanAmnt_total_rate\"] = data[\"loanAmnt\"] / data[\"totalAcc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若存在消极信息(有违约、破坏公物、信用未结)则标记为1\n",
    "data[\"Negative\"] = 0\n",
    "data[data[\"delinquency_2years\"] > 0][\"Negative\"] = 1\n",
    "data[data[\"openAcc\"] > 0][\"Negative\"] = 1\n",
    "data[data[\"pubRec\"] > 0][\"Negative\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先对employmentLength进行转换到数值（就业年限）\n",
    "data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "data['employmentLength'].replace('< 1 year', '0 years', inplace=True)\n",
    "\n",
    "def employmentLength_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "    \n",
    "data['employmentLength'] = data['employmentLength'].apply(employmentLength_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对earliesCreditLine进行预处理取年份和月份，年份直接使用int类型，月份转换成one-hot编码\n",
    "data['year'] = data['earliesCreditLine'].apply(lambda s: int(s[-4:]))\n",
    "data['month'] = data['earliesCreditLine'].apply(lambda x: str(x[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 部分类别特征\n",
    "# cate_features = ['grade', 'subGrade', 'employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode', 'applicationType', 'initialListStatus', 'title']\n",
    "\n",
    "# for f in cate_features:\n",
    "#     print(f, '类型数：', data[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade = dict(zip(sorted(list(set(data['grade']))),range(0,len(set(data['grade'])))))\n",
    "# data['grade_id'] = data['grade'].map(grade)\n",
    "\n",
    "# sub_grade = dict(zip(sorted(list(set(data['subGrade']))),range(0,len(set(data['subGrade'])))))\n",
    "# data['subgrade_id'] = data['subGrade'].map(sub_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类型数在2之上，又不是高维稀疏的转换成one-hot编码\n",
    "data = pd.get_dummies(data, columns=['homeOwnership', 'verificationStatus', 'purpose', 'regionCode', 'month'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding 完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# （labelEncode）\n",
    "for col in tqdm(['grade', 'subGrade', 'employmentTitle', 'postCode', 'title']):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(data[col].astype(str).values))\n",
    "    data[col] = le.transform(list(data[col].astype(str).values))\n",
    "print('Label Encoding 完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转化成时间格式\n",
    "for data in [data]:\n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'],format='%Y-%m-%d')\n",
    "    startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "    #构造时间特征\n",
    "    data['issueDateDT'] = data['issueDate'].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['grade', 'subGrade']: \n",
    "    temp_dict = data.groupby([col])['isDefault'].agg(['mean']).reset_index().rename(columns={'mean': col + '_target_mean'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col + '_target_mean'].to_dict()\n",
    "\n",
    "    data[col + '_target_mean'] = data[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['grade', 'subGrade']: \n",
    "    temp_dict = data.groupby([col])['isDefault'].agg(['std']).reset_index().rename(columns={'std': col + '_target_std'})\n",
    "    temp_dict.index = temp_dict[col].values\n",
    "    temp_dict = temp_dict[col + '_target_std'].to_dict()\n",
    "\n",
    "    data[col + '_target_std'] = data[col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"id\",\"issueDate\", \"earliesCreditLine\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取一些排序特征\n",
    "data['issueDate_Rank'] = data[\"issueDateDT\"].rank()\n",
    "data['revolBal_Rank'] = data[\"revolBal\"].rank()\n",
    "data['dti_Rank'] = data[\"dti\"].rank()\n",
    "data['revolUtil_Rank'] = data[\"revolUtil\"].rank()\n",
    "data['employmentTitle_Rank'] = data[\"employmentTitle\"].rank()\n",
    "data['annualIncome_Rank'] = data[\"annualIncome\"].rank()\n",
    "data['postCode_Rank'] = data[\"postCode\"].rank()\n",
    "data['year_Rank'] = data[\"year\"].rank()\n",
    "data['loanAmnt_annuallncome_rate_Rank'] = data[\"loanAmnt_annuallncome_rate\"].rank()\n",
    "data['interestRate_Rank'] = data[\"interestRate\"].rank()\n",
    "data['howlong_return_Rank'] = data[\"howlong_return\"].rank()\n",
    "data['installment_Rank'] = data[\"installment\"].rank()\n",
    "data['employmentLength_Rank'] = data[\"employmentLength\"].rank()\n",
    "data['loanAmnt_Rank'] = data[\"loanAmnt\"].rank()\n",
    "data['n6_Rank'] = data[\"n6\"].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.isDefault.notnull()].reset_index(drop=True)\n",
    "test = data[data.isDefault.isnull()].reset_index(drop=True)\n",
    "\n",
    "train = train.drop([\"isDefault\"], axis=1)\n",
    "test = test.drop([\"isDefault\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 1108\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test_pred = np.zeros(test_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "    importance = np.zeros(train_x.columns.shape[0])\n",
    "    \n",
    "    cv_scores = []\n",
    "    feature_names = train_x.columns.tolist()\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'tree_method':'gpu_hist',\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.05,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs':24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "            \n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'tree_method':'gpu_hist',\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.04,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "            \n",
    "        # importance += model.feature_importance() / 5\n",
    "        \n",
    "        train[valid_index] = val_pred\n",
    "        test += test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "    \n",
    "    # df = pd.DataFrame({ 'column': feature_names, 'importance': importance}).sort_values(by='importance')           \n",
    "    # df.to_csv(\"./importance.csv\")\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return test\n",
    "\n",
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\")\n",
    "    return cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test = xgb_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.774443\tvalid_1's auc: 0.766825\n",
      "[400]\ttraining's auc: 0.782765\tvalid_1's auc: 0.769319\n",
      "[600]\ttraining's auc: 0.788808\tvalid_1's auc: 0.769938\n",
      "[800]\ttraining's auc: 0.794624\tvalid_1's auc: 0.770502\n",
      "[1000]\ttraining's auc: 0.799741\tvalid_1's auc: 0.770682\n",
      "[1200]\ttraining's auc: 0.80449\tvalid_1's auc: 0.770846\n",
      "[1400]\ttraining's auc: 0.809421\tvalid_1's auc: 0.770923\n",
      "Early stopping, best iteration is:\n",
      "[1335]\ttraining's auc: 0.807932\tvalid_1's auc: 0.770946\n",
      "[0.7709456944036956]\n",
      "************************************ 2 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.773886\tvalid_1's auc: 0.768426\n",
      "[400]\ttraining's auc: 0.782285\tvalid_1's auc: 0.77102\n",
      "[600]\ttraining's auc: 0.78838\tvalid_1's auc: 0.771636\n",
      "[800]\ttraining's auc: 0.794025\tvalid_1's auc: 0.772014\n",
      "[1000]\ttraining's auc: 0.799034\tvalid_1's auc: 0.772177\n",
      "[1200]\ttraining's auc: 0.803985\tvalid_1's auc: 0.772245\n",
      "[1400]\ttraining's auc: 0.808834\tvalid_1's auc: 0.772155\n",
      "Early stopping, best iteration is:\n",
      "[1206]\ttraining's auc: 0.804158\tvalid_1's auc: 0.772268\n",
      "[0.7709456944036956, 0.7722676214504429]\n",
      "************************************ 3 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.77455\tvalid_1's auc: 0.766144\n",
      "[400]\ttraining's auc: 0.782938\tvalid_1's auc: 0.768876\n",
      "[600]\ttraining's auc: 0.789005\tvalid_1's auc: 0.76954\n",
      "[800]\ttraining's auc: 0.794491\tvalid_1's auc: 0.769885\n",
      "[1000]\ttraining's auc: 0.799825\tvalid_1's auc: 0.77012\n",
      "[1200]\ttraining's auc: 0.804721\tvalid_1's auc: 0.770223\n",
      "Early stopping, best iteration is:\n",
      "[1113]\ttraining's auc: 0.802595\tvalid_1's auc: 0.770271\n",
      "[0.7709456944036956, 0.7722676214504429, 0.770270847893509]\n",
      "************************************ 4 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.77354\tvalid_1's auc: 0.77025\n",
      "[400]\ttraining's auc: 0.782004\tvalid_1's auc: 0.772985\n",
      "[600]\ttraining's auc: 0.788081\tvalid_1's auc: 0.77363\n",
      "[800]\ttraining's auc: 0.793763\tvalid_1's auc: 0.773963\n",
      "[1000]\ttraining's auc: 0.798846\tvalid_1's auc: 0.774219\n",
      "[1200]\ttraining's auc: 0.803819\tvalid_1's auc: 0.774331\n",
      "[1400]\ttraining's auc: 0.808517\tvalid_1's auc: 0.774312\n",
      "Early stopping, best iteration is:\n",
      "[1226]\ttraining's auc: 0.8044\tvalid_1's auc: 0.774341\n",
      "[0.7709456944036956, 0.7722676214504429, 0.770270847893509, 0.7743406665682571]\n",
      "************************************ 5 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.774432\tvalid_1's auc: 0.766461\n",
      "[400]\ttraining's auc: 0.782718\tvalid_1's auc: 0.769013\n",
      "[600]\ttraining's auc: 0.788819\tvalid_1's auc: 0.769702\n",
      "[800]\ttraining's auc: 0.79446\tvalid_1's auc: 0.770145\n",
      "[1000]\ttraining's auc: 0.799644\tvalid_1's auc: 0.770315\n",
      "[1200]\ttraining's auc: 0.804311\tvalid_1's auc: 0.770441\n",
      "Early stopping, best iteration is:\n",
      "[1176]\ttraining's auc: 0.803779\tvalid_1's auc: 0.77046\n",
      "[0.7709456944036956, 0.7722676214504429, 0.770270847893509, 0.7743406665682571, 0.7704603625822689]\n",
      "lgb_scotrainre_list: [0.7709456944036956, 0.7722676214504429, 0.770270847893509, 0.7743406665682571, 0.7704603625822689]\n",
      "lgb_score_mean: 0.7716570385796346\n",
      "lgb_score_std: 0.0015122327348035594\n"
     ]
    }
   ],
   "source": [
    "lgb_test = lgb_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_test = cat_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9999f840e550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(xgb_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38125.35246299481\n"
     ]
    }
   ],
   "source": [
    "print(lgb_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7355\n",
    "rh_test = lgb_test * 0.33 + xgb_test * 0.34 + cat_test * 0.33\n",
    "test_data['isDefault'] = rh_test\n",
    "test_data[['id','isDefault']].to_csv('test_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data['isDefault'] = lgb_test\n",
    "# test_data[['id','isDefault']].to_csv('test_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
