{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_data = pd.read_csv('E:/Loan_default/train.csv')\n",
    "test_data = pd.read_csv('E:/Loan_default/testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_data[\"isDefault\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练集和测试集进行连接\n",
    "data = pd.concat([train_data, test_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先对employmentLength进行转换到数值（就业年限）\n",
    "data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "data['employmentLength'].replace('< 1 year', '0 years', inplace=True)\n",
    "\n",
    "def employmentLength_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "    \n",
    "data['employmentLength'] = data['employmentLength'].apply(employmentLength_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对earliesCreditLine进行预处理（取年份，舍去月份）月份之后进行提取\n",
    "data['earliesCreditLine'] = data['earliesCreditLine'].apply(lambda s: int(s[-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数值型特征：['id', 'loanAmnt', 'term', 'interestRate', 'installment', 'employmentTitle', 'homeOwnership', 'annualIncome', 'verificationStatus', 'purpose', 'postCode', 'regionCode', 'dti', 'delinquency_2years', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc', 'initialListStatus', 'applicationType', 'title', 'policyCode', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n",
      "\n",
      "object类型特征：['grade', 'subGrade', 'employmentLength', 'issueDate', 'isDefault', 'earliesCreditLine']\n"
     ]
    }
   ],
   "source": [
    "# 获取数值型特征(int or float)\n",
    "numerical_fea = list(train_data.select_dtypes(exclude=['object']).columns)\n",
    "numerical_fea.remove(\"isDefault\")\n",
    "print(\"数值型特征：\" + str(numerical_fea))\n",
    "print()\n",
    "# 类别特征\n",
    "category_fea = list(filter(lambda x: x not in numerical_fea,list(train_data.columns)))\n",
    "print(\"object类型特征：\" + str(category_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照平均数填充数值型特征\n",
    "data[numerical_fea] = data[numerical_fea].fillna(data[numerical_fea].median())\n",
    "data[numerical_fea] = data[numerical_fea].fillna(data[numerical_fea].median())\n",
    "#按照众数填充类别型特征\n",
    "data[category_fea] = data[category_fea].fillna(data[category_fea].mode())\n",
    "data[category_fea] = data[category_fea].fillna(data[category_fea].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade 类型数： 7\n",
      "subGrade 类型数： 35\n",
      "employmentTitle 类型数： 298101\n",
      "homeOwnership 类型数： 6\n",
      "verificationStatus 类型数： 3\n",
      "purpose 类型数： 14\n",
      "postCode 类型数： 935\n",
      "regionCode 类型数： 51\n",
      "applicationType 类型数： 2\n",
      "initialListStatus 类型数： 2\n",
      "title 类型数： 47903\n"
     ]
    }
   ],
   "source": [
    "# 部分类别特征\n",
    "cate_features = ['grade', 'subGrade', 'employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode', 'applicationType', 'initialListStatus', 'title']\n",
    "\n",
    "for f in cate_features:\n",
    "    print(f, '类型数：', data[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类型数在2之上，又不是高维稀疏的转换成one-hot编码\n",
    "data = pd.get_dummies(data, columns=['homeOwnership', 'verificationStatus', 'purpose', 'regionCode'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding 完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 高维类别特征需要进行转换（labelEmcode）\n",
    "for col in tqdm(['grade', 'subGrade', 'employmentTitle', 'postCode', 'title']):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(data[col].astype(str).values))\n",
    "    data[col] = le.transform(list(data[col].astype(str).values))\n",
    "print('Label Encoding 完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转化成时间格式\n",
    "for data in [data]:\n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'],format='%Y-%m-%d')\n",
    "    startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "    #构造时间特征\n",
    "    data['issueDateDT'] = data['issueDate'].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in data.columns if f not in ['id','issueDate', \"policyCode\", \"isDefault\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.isDefault.notnull()].reset_index(drop=True)\n",
    "test = data[data.isDefault.isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[features]\n",
    "test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(clf, train_x, train_y, test_x):\n",
    "    folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "    \n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        \n",
    "        train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "        valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "        params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.1,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs':24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "        }\n",
    "\n",
    "        model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "        val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "        test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "\n",
    "        train[valid_index] = val_pred\n",
    "        test = test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "       \n",
    "    print(\"scotrainre_list:\" + str(cv_scores))\n",
    "    print(\"score_mean:\" + str(np.mean(cv_scores)))\n",
    "    print(\"score_std:\" + str(np.std(cv_scores)))\n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.747577\tvalid_1's auc: 0.73613\n",
      "[400]\ttraining's auc: 0.759683\tvalid_1's auc: 0.737034\n",
      "[600]\ttraining's auc: 0.769404\tvalid_1's auc: 0.737373\n",
      "[800]\ttraining's auc: 0.778812\tvalid_1's auc: 0.737147\n",
      "Early stopping, best iteration is:\n",
      "[629]\ttraining's auc: 0.770887\tvalid_1's auc: 0.737409\n",
      "[0.7374089726344591]\n",
      "************************************ 2 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.748467\tvalid_1's auc: 0.732793\n",
      "[400]\ttraining's auc: 0.760113\tvalid_1's auc: 0.733569\n",
      "[600]\ttraining's auc: 0.770514\tvalid_1's auc: 0.733794\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttraining's auc: 0.770157\tvalid_1's auc: 0.73383\n",
      "[0.7374089726344591, 0.733829998420346]\n",
      "************************************ 3 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.747533\tvalid_1's auc: 0.736165\n",
      "[400]\ttraining's auc: 0.759425\tvalid_1's auc: 0.737132\n",
      "[600]\ttraining's auc: 0.769644\tvalid_1's auc: 0.737441\n",
      "[800]\ttraining's auc: 0.779177\tvalid_1's auc: 0.737484\n",
      "Early stopping, best iteration is:\n",
      "[770]\ttraining's auc: 0.777757\tvalid_1's auc: 0.737613\n",
      "[0.7374089726344591, 0.733829998420346, 0.7376129698893822]\n",
      "************************************ 4 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.747666\tvalid_1's auc: 0.735524\n",
      "[400]\ttraining's auc: 0.759499\tvalid_1's auc: 0.736614\n",
      "[600]\ttraining's auc: 0.769555\tvalid_1's auc: 0.736686\n",
      "Early stopping, best iteration is:\n",
      "[472]\ttraining's auc: 0.763275\tvalid_1's auc: 0.736779\n",
      "[0.7374089726344591, 0.733829998420346, 0.7376129698893822, 0.7367787454775053]\n",
      "************************************ 5 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.747852\tvalid_1's auc: 0.734363\n",
      "[400]\ttraining's auc: 0.759685\tvalid_1's auc: 0.735472\n",
      "[600]\ttraining's auc: 0.770042\tvalid_1's auc: 0.735621\n",
      "Early stopping, best iteration is:\n",
      "[551]\ttraining's auc: 0.7677\tvalid_1's auc: 0.735658\n",
      "[0.7374089726344591, 0.733829998420346, 0.7376129698893822, 0.7367787454775053, 0.7356577511267441]\n",
      "scotrainre_list:[0.7374089726344591, 0.733829998420346, 0.7376129698893822, 0.7367787454775053, 0.7356577511267441]\n",
      "score_mean:0.7362576875096873\n",
      "score_std:0.0013919301096782574\n"
     ]
    }
   ],
   "source": [
    "train, test = lgb_model(lgb,train,label,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['isDefault'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[['id','isDefault']].to_csv('test_sub_tianchong.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
