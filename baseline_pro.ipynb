{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "warnings.filterwarnings('ignore')\n",
    "# 数据读取\n",
    "train_data = pd.read_csv('I:/Loan_default/train.csv')\n",
    "test_data = pd.read_csv('I:/Loan_default/testA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签\n",
    "label = train_data[\"isDefault\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练集和测试集进行连接\n",
    "data = pd.concat([train_data, test_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先对employmentLength进行转换到数值（就业年限）\n",
    "data['employmentLength'].replace(to_replace='10+ years', value='10 years', inplace=True)\n",
    "data['employmentLength'].replace('< 1 year', '0 years', inplace=True)\n",
    "\n",
    "def employmentLength_to_int(s):\n",
    "    if pd.isnull(s):\n",
    "        return s\n",
    "    else:\n",
    "        return np.int8(s.split()[0])\n",
    "    \n",
    "data['employmentLength'] = data['employmentLength'].apply(employmentLength_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对earliesCreditLine进行预处理取年份和月份，年份直接使用int类型，月份转换成one-hot编码\n",
    "data['year'] = data['earliesCreditLine'].apply(lambda s: int(s[-4:]))\n",
    "data['month'] = data['earliesCreditLine'].apply(lambda x: str(x[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数值型特征：['id', 'loanAmnt', 'term', 'interestRate', 'installment', 'employmentTitle', 'homeOwnership', 'annualIncome', 'verificationStatus', 'purpose', 'postCode', 'regionCode', 'dti', 'delinquency_2years', 'ficoRangeLow', 'ficoRangeHigh', 'openAcc', 'pubRec', 'pubRecBankruptcies', 'revolBal', 'revolUtil', 'totalAcc', 'initialListStatus', 'applicationType', 'title', 'policyCode', 'n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14']\n",
      "\n",
      "object类型特征：['grade', 'subGrade', 'employmentLength', 'issueDate', 'isDefault', 'earliesCreditLine']\n"
     ]
    }
   ],
   "source": [
    "# 获取数值型特征(int or float)\n",
    "numerical_fea = list(train_data.select_dtypes(exclude=['object']).columns)\n",
    "numerical_fea.remove(\"isDefault\")\n",
    "print(\"数值型特征：\" + str(numerical_fea))\n",
    "print()\n",
    "# 类别特征\n",
    "category_fea = list(filter(lambda x: x not in numerical_fea,list(train_data.columns)))\n",
    "print(\"object类型特征：\" + str(category_fea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'填充完分数降了'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"填充完分数降了\"\"\"\n",
    "# #按照平均数填充数值型特征\n",
    "# data[numerical_fea] = data[numerical_fea].fillna(data[numerical_fea].median())\n",
    "# data[numerical_fea] = data[numerical_fea].fillna(data[numerical_fea].median())\n",
    "# #按照众数填充类别型特征\n",
    "# data[category_fea] = data[category_fea].fillna(data[category_fea].mode())\n",
    "# data[category_fea] = data[category_fea].fillna(data[category_fea].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade 类型数： 7\n",
      "subGrade 类型数： 35\n",
      "employmentTitle 类型数： 298101\n",
      "homeOwnership 类型数： 6\n",
      "verificationStatus 类型数： 3\n",
      "purpose 类型数： 14\n",
      "postCode 类型数： 935\n",
      "regionCode 类型数： 51\n",
      "applicationType 类型数： 2\n",
      "initialListStatus 类型数： 2\n",
      "title 类型数： 47903\n"
     ]
    }
   ],
   "source": [
    "# 部分类别特征\n",
    "cate_features = ['grade', 'subGrade', 'employmentTitle', 'homeOwnership', 'verificationStatus', 'purpose', 'postCode', 'regionCode', 'applicationType', 'initialListStatus', 'title']\n",
    "\n",
    "for f in cate_features:\n",
    "    print(f, '类型数：', data[f].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类型数在2之上，又不是高维稀疏的转换成one-hot编码\n",
    "data = pd.get_dummies(data, columns=['homeOwnership', 'verificationStatus', 'purpose', 'regionCode', 'month'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding 完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 高维类别特征需要进行转换（labelEmcode）\n",
    "for col in tqdm(['grade', 'subGrade', 'employmentTitle', 'postCode', 'title']):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(data[col].astype(str).values))\n",
    "    data[col] = le.transform(list(data[col].astype(str).values))\n",
    "print('Label Encoding 完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转化成时间格式\n",
    "for data in [data]:\n",
    "    data['issueDate'] = pd.to_datetime(data['issueDate'],format='%Y-%m-%d')\n",
    "    startdate = datetime.datetime.strptime('2007-06-01', '%Y-%m-%d')\n",
    "    #构造时间特征\n",
    "    data['issueDateDT'] = data['issueDate'].apply(lambda x: x-startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "id:无用特征\n",
    "issueDate:构造成为时间特征\n",
    "policyCode：唯一特征无意义\n",
    "isDefault：标签\n",
    "\"\"\"\n",
    "features = [f for f in data.columns if f not in ['id','issueDate', \"policyCode\", \"isDefault\",\"earliesCreditLine\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.isDefault.notnull()].reset_index(drop=True)\n",
    "test = data[data.isDefault.isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[features]\n",
    "test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lgb_model(clf, train_x, train_y, test_x):\n",
    "#     folds = 5\n",
    "#     seed = 1108\n",
    "#     kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "#     train = np.zeros(train_x.shape[0])\n",
    "#     test = np.zeros(test_x.shape[0])\n",
    "\n",
    "#     cv_scores = []\n",
    "    \n",
    "#     for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "#         print('************************************ {} ************************************'.format(str(i+1)))\n",
    "#         trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        \n",
    "#         train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "#         valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "#         params = {\n",
    "#                 'boosting_type': 'gbdt',\n",
    "#                 'objective': 'binary',\n",
    "#                 'metric': 'auc',\n",
    "#                 'min_child_weight': 5,\n",
    "#                 'num_leaves': 2 ** 5,\n",
    "#                 'lambda_l2': 10,\n",
    "#                 'feature_fraction': 0.8,\n",
    "#                 'bagging_fraction': 0.8,\n",
    "#                 'bagging_freq': 4,\n",
    "#                 'learning_rate': 0.1,\n",
    "#                 'seed': 2020,\n",
    "#                 'nthread': 28,\n",
    "#                 'n_jobs':24,\n",
    "#                 'silent': True,\n",
    "#                 'verbose': -1,\n",
    "#         }\n",
    "\n",
    "#         model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "#         val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "#         test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "\n",
    "#         train[valid_index] = val_pred\n",
    "#         test = test_pred / kf.n_splits\n",
    "#         cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "#         print(cv_scores)\n",
    "       \n",
    "#     print(\"scotrainre_list:\" + str(cv_scores))\n",
    "#     print(\"score_mean:\" + str(np.mean(cv_scores)))\n",
    "#     print(\"score_std:\" + str(np.std(cv_scores)))\n",
    "#     return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lgb, test_lgb = lgb_model(lgb,train,label,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 2020\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.1,\n",
    "                'seed': 2020,\n",
    "                'nthread': 28,\n",
    "                'n_jobs':24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "            # print(list(sorted(zip(features, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.04,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 2020,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "        train[valid_index] = val_pred\n",
    "        test = test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "       \n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return test\n",
    "\n",
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\")\n",
    "    return cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test = xgb_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.748264\tvalid_1's auc: 0.736581\n",
      "[400]\ttraining's auc: 0.760463\tvalid_1's auc: 0.737697\n",
      "[600]\ttraining's auc: 0.770741\tvalid_1's auc: 0.737789\n",
      "Early stopping, best iteration is:\n",
      "[546]\ttraining's auc: 0.768013\tvalid_1's auc: 0.737879\n",
      "[0.7378792764530935]\n",
      "************************************ 2 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.749135\tvalid_1's auc: 0.733188\n",
      "[400]\ttraining's auc: 0.761151\tvalid_1's auc: 0.733894\n",
      "[600]\ttraining's auc: 0.771305\tvalid_1's auc: 0.734359\n",
      "[800]\ttraining's auc: 0.781055\tvalid_1's auc: 0.73433\n",
      "Early stopping, best iteration is:\n",
      "[600]\ttraining's auc: 0.771305\tvalid_1's auc: 0.734359\n",
      "[0.7378792764530935, 0.734358796091941]\n",
      "************************************ 3 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.748093\tvalid_1's auc: 0.736453\n",
      "[400]\ttraining's auc: 0.759972\tvalid_1's auc: 0.737232\n",
      "[600]\ttraining's auc: 0.770566\tvalid_1's auc: 0.737448\n",
      "Early stopping, best iteration is:\n",
      "[596]\ttraining's auc: 0.770382\tvalid_1's auc: 0.73746\n",
      "[0.7378792764530935, 0.734358796091941, 0.7374604376356189]\n",
      "************************************ 4 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.748352\tvalid_1's auc: 0.736322\n",
      "[400]\ttraining's auc: 0.760413\tvalid_1's auc: 0.73729\n",
      "[600]\ttraining's auc: 0.770601\tvalid_1's auc: 0.737618\n",
      "Early stopping, best iteration is:\n",
      "[593]\ttraining's auc: 0.770304\tvalid_1's auc: 0.737669\n",
      "[0.7378792764530935, 0.734358796091941, 0.7374604376356189, 0.7376691723771822]\n",
      "************************************ 5 ************************************\n",
      "[LightGBM] [Warning] num_threads is set with nthread=28, will be overridden by n_jobs=24. Current value: num_threads=24\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.748351\tvalid_1's auc: 0.734747\n",
      "[400]\ttraining's auc: 0.760352\tvalid_1's auc: 0.735524\n",
      "[600]\ttraining's auc: 0.771012\tvalid_1's auc: 0.735828\n",
      "[800]\ttraining's auc: 0.780546\tvalid_1's auc: 0.735893\n",
      "Early stopping, best iteration is:\n",
      "[783]\ttraining's auc: 0.779791\tvalid_1's auc: 0.735936\n",
      "[0.7378792764530935, 0.734358796091941, 0.7374604376356189, 0.7376691723771822, 0.7359355922775359]\n",
      "lgb_scotrainre_list: [0.7378792764530935, 0.734358796091941, 0.7374604376356189, 0.7376691723771822, 0.7359355922775359]\n",
      "lgb_score_mean: 0.7366606549670742\n",
      "lgb_score_std: 0.0013391092706999867\n"
     ]
    }
   ],
   "source": [
    "lgb_test = lgb_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "0:\tlearn: 0.3985448\ttest: 0.3966307\tbest: 0.3966307 (0)\ttotal: 44.2ms\tremaining: 14m 43s\n",
      "500:\tlearn: 0.3757458\ttest: 0.3744098\tbest: 0.3744098 (500)\ttotal: 20.4s\tremaining: 13m 15s\n",
      "1000:\tlearn: 0.3742569\ttest: 0.3737271\tbest: 0.3737265 (999)\ttotal: 40.4s\tremaining: 12m 46s\n",
      "1500:\tlearn: 0.3732264\ttest: 0.3734521\tbest: 0.3734521 (1500)\ttotal: 1m\tremaining: 12m 23s\n",
      "2000:\tlearn: 0.3723491\ttest: 0.3732803\tbest: 0.3732799 (1999)\ttotal: 1m 20s\tremaining: 12m 3s\n",
      "2500:\tlearn: 0.3715715\ttest: 0.3731855\tbest: 0.3731855 (2500)\ttotal: 1m 40s\tremaining: 11m 41s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3731568729\n",
      "bestIteration = 2632\n",
      "\n",
      "Shrink model to first 2633 iterations.\n",
      "[0.7376935598491381]\n",
      "************************************ 2 ************************************\n",
      "0:\tlearn: 0.3979770\ttest: 0.3989152\tbest: 0.3989152 (0)\ttotal: 46.9ms\tremaining: 15m 38s\n",
      "500:\tlearn: 0.3750411\ttest: 0.3771476\tbest: 0.3771476 (500)\ttotal: 20.2s\tremaining: 13m 4s\n",
      "1000:\tlearn: 0.3735818\ttest: 0.3764074\tbest: 0.3764074 (1000)\ttotal: 39.9s\tremaining: 12m 37s\n",
      "1500:\tlearn: 0.3725491\ttest: 0.3760853\tbest: 0.3760848 (1499)\ttotal: 59.5s\tremaining: 12m 13s\n",
      "2000:\tlearn: 0.3716921\ttest: 0.3759134\tbest: 0.3759127 (1993)\ttotal: 1m 19s\tremaining: 11m 51s\n",
      "2500:\tlearn: 0.3709151\ttest: 0.3757808\tbest: 0.3757805 (2498)\ttotal: 1m 38s\tremaining: 11m 30s\n",
      "3000:\tlearn: 0.3701676\ttest: 0.3756793\tbest: 0.3756792 (2998)\ttotal: 1m 58s\tremaining: 11m 10s\n",
      "3500:\tlearn: 0.3694821\ttest: 0.3756377\tbest: 0.3756371 (3495)\ttotal: 2m 17s\tremaining: 10m 50s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3756318391\n",
      "bestIteration = 3540\n",
      "\n",
      "Shrink model to first 3541 iterations.\n",
      "[0.7376935598491381, 0.7353422709417781]\n",
      "************************************ 3 ************************************\n",
      "0:\tlearn: 0.3979606\ttest: 0.3986948\tbest: 0.3986948 (0)\ttotal: 48.3ms\tremaining: 16m 6s\n",
      "500:\tlearn: 0.3753201\ttest: 0.3762249\tbest: 0.3762249 (500)\ttotal: 20.6s\tremaining: 13m 20s\n",
      "1000:\tlearn: 0.3738261\ttest: 0.3754829\tbest: 0.3754829 (1000)\ttotal: 40.4s\tremaining: 12m 47s\n",
      "1500:\tlearn: 0.3727973\ttest: 0.3751656\tbest: 0.3751656 (1500)\ttotal: 1m\tremaining: 12m 21s\n",
      "2000:\tlearn: 0.3719463\ttest: 0.3750169\tbest: 0.3750166 (1999)\ttotal: 1m 19s\tremaining: 11m 57s\n",
      "2500:\tlearn: 0.3711520\ttest: 0.3748996\tbest: 0.3748996 (2500)\ttotal: 1m 39s\tremaining: 11m 36s\n",
      "3000:\tlearn: 0.3704264\ttest: 0.3748137\tbest: 0.3748123 (2992)\ttotal: 1m 59s\tremaining: 11m 15s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3748080236\n",
      "bestIteration = 3079\n",
      "\n",
      "Shrink model to first 3080 iterations.\n",
      "[0.7376935598491381, 0.7353422709417781, 0.7383981417738797]\n",
      "************************************ 4 ************************************\n",
      "0:\tlearn: 0.3980454\ttest: 0.3983470\tbest: 0.3983470 (0)\ttotal: 48ms\tremaining: 15m 59s\n",
      "500:\tlearn: 0.3753152\ttest: 0.3762589\tbest: 0.3762589 (500)\ttotal: 20.2s\tremaining: 13m 4s\n",
      "1000:\tlearn: 0.3738623\ttest: 0.3754894\tbest: 0.3754894 (1000)\ttotal: 39.8s\tremaining: 12m 36s\n",
      "1500:\tlearn: 0.3728541\ttest: 0.3751433\tbest: 0.3751433 (1500)\ttotal: 59.5s\tremaining: 12m 13s\n",
      "2000:\tlearn: 0.3719817\ttest: 0.3749473\tbest: 0.3749470 (1998)\ttotal: 1m 19s\tremaining: 11m 52s\n",
      "2500:\tlearn: 0.3712103\ttest: 0.3748333\tbest: 0.3748333 (2500)\ttotal: 1m 38s\tremaining: 11m 31s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3747681302\n",
      "bestIteration = 2770\n",
      "\n",
      "Shrink model to first 2771 iterations.\n",
      "[0.7376935598491381, 0.7353422709417781, 0.7383981417738797, 0.7375544288576115]\n",
      "************************************ 5 ************************************\n",
      "0:\tlearn: 0.3981111\ttest: 0.3980670\tbest: 0.3980670 (0)\ttotal: 46.1ms\tremaining: 15m 21s\n",
      "500:\tlearn: 0.3753087\ttest: 0.3762075\tbest: 0.3762075 (500)\ttotal: 20.2s\tremaining: 13m 4s\n",
      "1000:\tlearn: 0.3738391\ttest: 0.3754934\tbest: 0.3754934 (1000)\ttotal: 40s\tremaining: 12m 39s\n",
      "1500:\tlearn: 0.3728355\ttest: 0.3751784\tbest: 0.3751777 (1498)\ttotal: 60s\tremaining: 12m 19s\n",
      "2000:\tlearn: 0.3719603\ttest: 0.3749689\tbest: 0.3749689 (2000)\ttotal: 1m 19s\tremaining: 11m 58s\n",
      "2500:\tlearn: 0.3711950\ttest: 0.3748371\tbest: 0.3748371 (2499)\ttotal: 1m 39s\tremaining: 11m 38s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3748337932\n",
      "bestIteration = 2505\n",
      "\n",
      "Shrink model to first 2506 iterations.\n",
      "[0.7376935598491381, 0.7353422709417781, 0.7383981417738797, 0.7375544288576115, 0.7360390424112879]\n",
      "cat_scotrainre_list: [0.7376935598491381, 0.7353422709417781, 0.7383981417738797, 0.7375544288576115, 0.7360390424112879]\n",
      "cat_score_mean: 0.737005488766739\n",
      "cat_score_std: 0.0011326580708520592\n"
     ]
    }
   ],
   "source": [
    "cat_test = cat_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7976.796"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7969.466260951486"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7984.467826934987"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7355\n",
    "rh_test = lgb_test*0.3 + xgb_test*0.4 + cat_test*0.3\n",
    "test_data['isDefault'] = rh_test\n",
    "test_data[['id','isDefault']].to_csv('test_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7333\n",
    "rh_test = cat_test\n",
    "test_data['isDefault'] = rh_test\n",
    "test_data[['id','isDefault']].to_csv('test_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7353\n",
    "rh_test = lgb_test*0.5 + xgb_test*0.5\n",
    "test_data['isDefault'] = rh_test\n",
    "test_data[['id','isDefault']].to_csv('test_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
